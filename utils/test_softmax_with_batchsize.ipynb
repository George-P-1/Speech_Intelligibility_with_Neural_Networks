{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Softmax withou Batch Size dimension included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d42b5a4b30>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual seed for reproducibility\n",
    "torch.manual_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
      "        1.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Weighted vector\n",
    "r = torch.linspace(0, 1, 10, device=device)\n",
    "print(f'r: {r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_vals: tensor([0.7680, 0.9209, 0.5808, 0.9348, 0.4126, 0.8324, 0.5017, 0.4167, 0.4569,\n",
      "        0.5755], device='cuda:0')\n",
      "random_vals shape: torch.Size([10])\n",
      "\n",
      "y (Softmax Output with Batch Size): \n",
      "tensor([0.1115, 0.1299, 0.0924, 0.1317, 0.0781, 0.1189, 0.0854, 0.0784, 0.0817,\n",
      "        0.0920], device='cuda:0')\n",
      "y shape: torch.Size([10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign an example 10 length vector to mimic the softmax output of a neural network with random values\n",
    "random_vals = torch.rand(10, device=device)\n",
    "print(f'random_vals: {random_vals}')\n",
    "print(f'random_vals shape: {random_vals.shape}\\n')\n",
    "\n",
    "y = torch.nn.functional.softmax(random_vals, dim=0)  # Softmax applied\n",
    "print(f'y (Softmax Output with Batch Size): \\n{y}')\n",
    "print(f'y shape: {y.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: tensor([0.0000, 0.0144, 0.0205, 0.0439, 0.0347, 0.0660, 0.0569, 0.0610, 0.0726,\n",
      "        0.0920], device='cuda:0')\n",
      "z shape: torch.Size([10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiply the weighted vector by the output of the neural network\n",
    "z = y * r\n",
    "print(f'z: {z}')\n",
    "print(f'z shape: {z.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_sum: 0.4621482491493225\n",
      "z_sum shape: torch.Size([])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sum the weighted output of the neural network\n",
    "z_sum = z.sum()\n",
    "print(f'z_sum: {z_sum}')\n",
    "print(f'z_sum shape: {z_sum.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Softmax with Batch Size dimension included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size of 4 (4 different inputs)\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_vals: tensor([[0.4792, 0.6304, 0.6253, 0.5403, 0.5927, 0.5233, 0.7243, 0.9497, 0.9851,\n",
      "         0.6574],\n",
      "        [0.2637, 0.7664, 0.2594, 0.9858, 0.6080, 0.4744, 0.7301, 0.0174, 0.6546,\n",
      "         0.3091],\n",
      "        [0.1780, 0.5495, 0.4082, 0.6069, 0.6019, 0.9756, 0.4606, 0.2527, 0.7743,\n",
      "         0.0104],\n",
      "        [0.2205, 0.4637, 0.3574, 0.5737, 0.4698, 0.4951, 0.5594, 0.0667, 0.8782,\n",
      "         0.0271]], device='cuda:0')\n",
      "random_vals shape: torch.Size([4, 10])\n",
      "\n",
      "y (Softmax Output with Batch Size): \n",
      "tensor([[0.0814, 0.0947, 0.0942, 0.0866, 0.0912, 0.0851, 0.1040, 0.1304, 0.1350,\n",
      "         0.0973],\n",
      "        [0.0754, 0.1247, 0.0751, 0.1553, 0.1065, 0.0931, 0.1203, 0.0590, 0.1115,\n",
      "         0.0790],\n",
      "        [0.0711, 0.1031, 0.0896, 0.1092, 0.1087, 0.1579, 0.0944, 0.0767, 0.1291,\n",
      "         0.0602],\n",
      "        [0.0803, 0.1023, 0.0920, 0.1143, 0.1030, 0.1056, 0.1126, 0.0688, 0.1549,\n",
      "         0.0661]], device='cuda:0')\n",
      "y shape: torch.Size([4, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign an example 10 length vector to mimic the softmax output of a neural network with random values\n",
    "random_vals = torch.rand(batch_size, 10, device=device)\n",
    "print(f'random_vals: {random_vals}')\n",
    "print(f'random_vals shape: {random_vals.shape}\\n')\n",
    "\n",
    "y = torch.nn.functional.softmax(random_vals, dim=1)\n",
    "print(f'y (Softmax Output with Batch Size): \\n{y}')\n",
    "print(f'y shape: {y.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z (Weighted Outputs): \n",
      "tensor([[0.0000, 0.0105, 0.0209, 0.0289, 0.0405, 0.0473, 0.0694, 0.1014, 0.1200,\n",
      "         0.0973],\n",
      "        [0.0000, 0.0139, 0.0167, 0.0518, 0.0473, 0.0517, 0.0802, 0.0459, 0.0991,\n",
      "         0.0790],\n",
      "        [0.0000, 0.0115, 0.0199, 0.0364, 0.0483, 0.0877, 0.0629, 0.0596, 0.1148,\n",
      "         0.0602],\n",
      "        [0.0000, 0.0114, 0.0205, 0.0381, 0.0458, 0.0587, 0.0751, 0.0535, 0.1377,\n",
      "         0.0661]], device='cuda:0')\n",
      "z shape: torch.Size([4, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiply the weighted vector by the output of the neural network\n",
    "z = y * r  # Element-wise multiplication (broadcasting)\n",
    "print(f'z (Weighted Outputs): \\n{z}')\n",
    "print(f'z shape: {z.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_sum (Final Predictions for Each Sample): tensor([0.5362, 0.4856, 0.5013, 0.5068], device='cuda:0')\n",
      "z_sum shape: torch.Size([4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sum along the last dimension to get the final prediction per sample\n",
    "z_sum = z.sum(dim=1)  # Sum along the 10-class dimension\n",
    "print(f'z_sum (Final Predictions for Each Sample): {z_sum}')\n",
    "print(f'z_sum shape: {z_sum.shape}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
